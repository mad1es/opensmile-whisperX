services:
  pipeline:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        TORCH_CHANNEL: cpu
    image: opensmile-whisperx:latest
    working_dir: /app
    volumes:
      - ./data:/app/data
      - ./cache:/root/.cache
    environment:
      - PYTHONPATH=/app
      - OPENSMILE_BIN=/app/opensmile/bin/SMILExtract
      - HF_HOME=/root/.cache/huggingface
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
    stdin_open: true
    tty: true
    profiles: ["cpu"]

  pipeline-gpu:
    extends:
      service: pipeline
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: pytorch/pytorch:2.4.1-cuda12.1-cudnn9-runtime
        TORCH_CHANNEL: cu121
    environment:
      - PYTHONPATH=/app
      - OPENSMILE_BIN=/app/opensmile/bin/SMILExtract
      - HF_HOME=/root/.cache/huggingface
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
    profiles: ["gpu"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: ["gpu"]


